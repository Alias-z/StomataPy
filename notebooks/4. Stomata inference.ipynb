{"cells":[{"cell_type":"markdown","metadata":{"id":"U3MaS_6MYjGC","pycharm":{"name":"#%% md\n"}},"source":["# **Starch detection from confocal stomatal images - training**\n","\n","Autors: Santelia Lab at ETH Zurich\n","\n","Contact: hongyuan.zhang@usys.ethz.ch"]},{"cell_type":"markdown","metadata":{"id":"A5do6svlEHtz","pycharm":{"name":"#%% md\n"}},"source":["## Reference\n","[MMDetection](https://github.com/open-mmlab/mmdetection)\n","<br><br>\n","[MMSegmentation](https://github.com/open-mmlab/mmsegmentation)\n","<br><br>\n","[Instance segmentation on COCO benchmark](https://paperswithcode.com/sota/instance-segmentation-on-coco)\n","<br><br>\n","[Semantic segmentation on ADE20K benchmark](https://paperswithcode.com/sota/semantic-segmentation-on-ade20k)\n","<br><br>\n","[Image classification on ImageNet benchmark](https://paperswithcode.com/sota/image-classification-on-imagenet)\n","<br><br>\n","[Masked-attention mask transformer for universal image segmentation (Mask2Former) by Cheng, Bowen, et al., 2022](https://arxiv.org/abs/2112.01527)\n","<br><br>"]},{"cell_type":"markdown","metadata":{"id":"jiw5WWuSEHt0","pycharm":{"name":"#%% md\n"}},"source":["### install mmdetection and mmsegmentation"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\zhongyua\\OneDrive\\Academics\\2023 ETH\\Projects\\PhD thesis\\StomataPy\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from stomatapy.models.openmmlab import OpenMMlab\n","from stomatapy.core.core import get_paths\n","\n","\n","root = 'Datasets/Koheler2023/stomatal density'\n","\n","folder_dirs = [os.path.join(root, folder) for folder in os.listdir(root)]\n","\n","for folder_dir in folder_dirs:\n","    subfolder_dirs = [os.path.join(folder_dir, subfolder) for subfolder in os.listdir(folder_dir)]\n","    for subfolder_dir in subfolder_dirs:\n","        \n","        image_paths = get_paths(subfolder_dir, '.png') + get_paths(subfolder_dir, '.tif') + get_paths(subfolder_dir, '.jpg')\n","\n","        test = OpenMMlab(\n","                detector_config_path='Checkpoints/Swin-S_Mask2Former_Koheler2023_0805/Swin-s_mask2former_config.py',\n","                detector_weight_path='Checkpoints/Swin-S_Mask2Former_Koheler2023_0805/best_coco_segm_mAP_epoch_149.pth',\n","                detector_threshold=0.8,\n","                segmentor_config_path='Checkpoints/Rein_Dinov2_Mask2Former_gmax/rein_dinov2_mask2former_config.py',\n","                segmentor_weight_path='Checkpoints/Rein_Dinov2_Mask2Former_gmax/dinov2_segmentor.pth',\n","                use_sahi=True\n","            ).detect_cell(image_paths, if_resize_image=True, if_visualize=False, if_auto_label=True)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 140/140 [16:29<00:00,  7.07s/it]\n"]}],"source":["import os\n","import json\n","import cv2\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd  # for Excel sheet\n","from matplotlib import pyplot as plt\n","from stomatapy.core.core import get_paths, imread_rgb\n","from stomatapy.core.isat import UtilsISAT\n","from stomatapy.utils.stoma_dimension import GetDiameter\n","\n","def if_seg_on_edges(seg_mask: np.ndarray, edge_width: int = 3) -> bool:\n","    \"\"\"Check if the segmentation mask has been cut off by any edges\"\"\"\n","    top_edge = seg_mask[:edge_width, :]  # pixels on the top edge\n","    bottom_edge = seg_mask[-edge_width:, :]  # bottom edge\n","    left_edge = seg_mask[:, :edge_width]  # left edge\n","    right_edge = seg_mask[:, -edge_width:]  # right edge\n","    edges = [top_edge, bottom_edge, left_edge, right_edge]  # all four edges\n","    return any(np.any(edge) for edge in edges)\n","\n","scale = 2.9  # scale (pixels per micron)\n","batch_results = pd.DataFrame()\n","\n","root = 'Datasets/Koheler2023/stomatal density'\n","folder_dirs = [os.path.join(root, folder) for folder in os.listdir(root)]\n","\n","for folder_dir in tqdm(folder_dirs, total=len(folder_dirs)):\n","    subfolder_dirs = [os.path.join(folder_dir, subfolder) for subfolder in os.listdir(folder_dir)]\n","    for subfolder_dir in subfolder_dirs: \n","        json_paths = get_paths(subfolder_dir, 'json')\n","        for json_path in json_paths:\n","            with open(json_path, 'r', encoding='utf-8') as file:\n","                data = json.load(file)  # load the json file\n","            image_name = data['info']['name']\n","            image_path = os.path.join(subfolder_dir, image_name)  # get the image path\n","            image = imread_rgb(image_path)  # load the image\n","            image_dimension = (data['info']['height'], data['info']['width'])  # get the image dimension\n","            for idx, obj in enumerate(data['objects']):\n","                overlay_color = np.array([0, 0, 255])\n","                mask = obj['segmentation']  # get the ISAT format segmentation mask\n","                mask_bool = UtilsISAT.segmentation2mask(mask, image_dimension)  # convert the ISAT mask to a bool mask\n","                if not if_seg_on_edges(mask_bool):\n","                    mask_area = np.sum(mask_bool) * (1 / scale) ** 2 # get the mask area\n","                    bbox = obj['bbox']  # get the object bbox\n","                    padding = max((bbox[2] - bbox[0]), (bbox[3] - bbox[1])) // 4  # calculate the padding value of the bbox as max 25% of either dimension\n","                    mask_filled = np.uint8(np.stack([mask_bool, mask_bool, mask_bool], axis=-1) * 255)  # fill in the bool mask with RGB white color for dimension\n","                    cropped_mask = UtilsISAT.crop_image_with_padding(mask_filled, bbox, padding, allow_negative_crop=True)  # crop the mask to be focused\n","                    dimension = GetDiameter(cropped_mask, shrink_ratio=0.8, line_thickness=1).pca()  # get the lenghth and the width of the object\n","                    length, width = dimension['length'] * (1 / scale), dimension['width'] * (1 / scale)  # convert the length and the width to microns\n","                    length_points, width_points = dimension['length_points'], dimension['width_points']\n","                    x_min_padded, y_min_padded = bbox[0] - padding, bbox[1] - padding\n","                    original_length_points = [(int(x + x_min_padded), int(y + y_min_padded)) for x, y in length_points]\n","                    original_width_points = [(int(x + x_min_padded), int(y + y_min_padded)) for x, y in width_points]\n","                    overlay_color = np.array([255, 0, 0])\n","                    cv2.line(image, original_length_points[0], original_length_points[1], (0, 255, 0), 2)  # draw the length\n","                    cv2.line(image, original_width_points[0], original_width_points[1], (0, 0, 255), 2)  # draw the width\n","                    result = {\n","                        'folder': os.path.dirname(folder_dir),\n","                        'subfolder': os.path.dirname(subfolder_dir),\n","                        'image_name': image_name,\n","                        'object_idx': idx,\n","                        'object_category': 'stomatal complex',\n","                        'area  (\\u03BCm\\N{SUPERSCRIPT TWO})': mask_area,\n","                        'length (\\u03BCm)': length,\n","                        'width (\\u03BCm)': width,\n","                        'angle (°)': dimension['angle'],\n","                    }\n","                    result = pd.DataFrame(data=[result])  # collect result in a pd dataframe for exporting to an Excel sheet\n","                    batch_results = pd.concat([batch_results, result], axis=0)  # concatenate all results\n","                image[mask_bool] = image[mask_bool] * 0.5 + overlay_color * 0.5  # create starch overlay on the original image\n","            cv2.imwrite(os.path.join(subfolder_dir, f'{os.path.splitext(image_name)[0]}_prediction.png'), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # export the image\n","batch_results.to_excel(os.path.join(root, 'results.xlsx'), index=False)  # export the summarized results to Excel    "]},{"cell_type":"markdown","metadata":{"id":"paeXlngsEHt2","pycharm":{"name":"#%% md\n"}},"source":["### check GPU availability"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\zhongyua\\OneDrive\\Academics\\2023 ETH\\Projects\\PhD thesis\\StomataPy\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["08/30/2024 15:45:04 - WARNING - xformers -   A matching Triton is not available, some optimizations will not be enabled.\n","Error caught was: No module named 'triton'\n"]},{"name":"stdout","output_type":"stream","text":["Loads checkpoint by local backend from path: Checkpoints/Rein_Dinov2_Mask2Former_Sun2021_0829/dinov2_segmentor.pth\n"]}],"source":["import os\n","from stomatapy.models.openmmlab import OpenMMlab\n","from stomatapy.core.core import get_paths\n","\n","\n","# input_dir = 'Datasets/Li2023/Processed/V. faba/Unlabeled'\n","input_dir = 'Datasets/Sun2023/Processed/T. aestivum'\n","image_paths = get_paths(input_dir, file_extension='.jpg')[:200]\n","json_paths = [os.path.splitext(image_path)[0] + '.json' for image_path in image_paths]\n","\n","models = OpenMMlab(\n","        detector_config_path='Checkpoints/Swin-S_Mask2Former_Sun2021_0826/Swin-s_mask2former_config.py',\n","        detector_weight_path='Checkpoints/Swin-S_Mask2Former_Sun2021_0826/best_coco_segm_mAP_epoch_231.pth',\n","        detector_threshold=0.8,\n","        segmentor_config_path='Checkpoints/Rein_Dinov2_Mask2Former_Sun2021_0829/rein_dinov2_mask2former_config.py',\n","        segmentor_weight_path='Checkpoints/Rein_Dinov2_Mask2Former_Sun2021_0829/dinov2_segmentor.pth',\n","        use_sahi=True\n","        )"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loads checkpoint by local backend from path: Checkpoints/Swin-S_Mask2Former_Sun2021_0826/best_coco_segm_mAP_epoch_231.pth\n","08/30 15:45:31 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 200/200 [26:06<00:00,  7.83s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Converting predictions to ISAT JSON files...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 200/200 [02:49<00:00,  1.18it/s]\n"]}],"source":["_ = models.detect_cell(image_paths)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 200/200 [17:19<00:00,  5.20s/it]\n"]}],"source":["_ = models.segment_cell(json_paths, if_visualize=False, if_auto_label=True)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\zhongyua\\OneDrive\\Academics\\2023 ETH\\Projects\\PhD thesis\\StomataPy\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loads checkpoint by local backend from path: Checkpoints/Swin-S_Mask2Former_temp_0822/best_coco_segm_mAP_epoch_295.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 68/68 [07:39<00:00,  6.75s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Converting predictions to ISAT JSON files...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 68/68 [00:21<00:00,  3.23it/s]\n"]}],"source":["import os\n","from stomatapy.models.openmmlab import OpenMMlab\n","from stomatapy.core.core import get_paths\n","\n","\n","input_dir = 'Datasets/Sun2021/Processed/T. aestivum/Unlabeled'\n","\n","image_paths = get_paths(input_dir, '.png') + get_paths(input_dir, '.tif') + get_paths(input_dir, '.jpg')\n","\n","test = OpenMMlab(\n","        detector_config_path='Checkpoints/Swin-S_Mask2Former_temp_0822/Swin-s_mask2former_config.py',\n","        detector_weight_path='Checkpoints/Swin-S_Mask2Former_temp_0822/best_coco_segm_mAP_epoch_295.pth',\n","        detector_threshold=0.8,\n","        segmentor_config_path='Checkpoints/Rein_Dinov2_Mask2Former_gmax/rein_dinov2_mask2former_config.py',\n","        segmentor_weight_path='Checkpoints/Rein_Dinov2_Mask2Former_gmax/dinov2_segmentor.pth',\n","        use_sahi=True\n","    ).detect_stomata(image_paths, if_resize_image=True, if_visualize=False, if_auto_label=True)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\zhongyua\\OneDrive\\Academics\\2023 ETH\\Projects\\PhD thesis\\StomataPy\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loads checkpoint by local backend from path: Checkpoints/Swin-S_Mask2Former_pvulgaris/best_coco_segm_mAP_epoch_145.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 164/164 [20:10<00:00,  7.38s/it]\n"]}],"source":["import os\n","from stomatapy.models.openmmlab import OpenMMlab\n","from stomatapy.core.core import get_paths\n","\n","\n","input_dir = 'Datasets/Casado-Garcia2020/Processed/P. vulgaris/Unlabeled - Copy'\n","image_paths = get_paths(input_dir, file_extension='.jpg')\n","\n","test = OpenMMlab(\n","    detector_config_path='Checkpoints/Swin-S_Mask2Former_pvulgaris/Swin-s_mask2former_config.py',\n","    detector_weight_path='Checkpoints/Swin-S_Mask2Former_pvulgaris/best_coco_segm_mAP_epoch_145.pth',\n","    detector_threshold=0.2,\n","    sahi_overlap_ratio=0.2,\n","    use_sahi=True\n","    ).detect_objects(image_paths=image_paths, if_resize_image=True, if_auto_label=True)"]},{"cell_type":"markdown","metadata":{"id":"LtUf885HCl2I"},"source":["## inference"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","      _____ ____ ____  ______   ___ _     ____  ____      _      ____ ____  \n","     / ___//    |    \\|      | /  _| |   |    |/    |    | |    /    |    \\ \n","    (   \\_|  o  |  _  |      |/  [_| |    |  ||  o  |    | |   |  o  |  o  )\n","     \\__  |     |  |  |_|  |_|    _| |___ |  ||     |    | |___|     |     |\n","     /  \\ |  _  |  |  | |  | |   [_|     ||  ||  _  |    |     |  _  |  O  |\n","     \\    |  |  |  |  | |  | |     |     ||  ||  |  |    |     |  |  |     |\n","      \\___|__|__|__|__| |__| |_____|_____|____|__|__|    |_____|__|__|_____|\n","    \n","\n"," \u001b[34m Done! \n","\n","\u001b[34m processed 0 images in 0.0 min\n","\u001b[34m detected 0 stomata and measured 0 stomata\n","\n"," \n"," \u001b[31m there is no image provided any use in this run; please check the following possibilities:\n","\n"," 1. check if your input directory is correct\n","\n"," 2. maybe you forgot to put the \"scale.txt\" file in your folder?\n","\n"," 3. is the image quality good enough?\n","\n"," 4. are image formats not supported? currently the program supports \n"," ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp', '.gif', '.ico', '.jfif', '.webp']\n"]}],"source":["from stomata_py.inference_api.stomata_inference import StomataSeeker\n","StomataSeeker(input_dir='Data//Trial 2',\n","              output_name='Results aperture',\n","              batch_size=20,\n","              concatenate_excels=True,\n","              ensemble_detectors=False,\n","              object_detector_config_path='Applications/Configs/OBJECT_Stomata_dino_swin-l.py',\n","              object_detector_weight_path='Applications/Weights/OBJECT_Stomata_dino_swin-l_2023August13.pth',\n","              object_detector_threshold=0.2,\n","              instance_detector_config_path='Applications/Configs/INSTANCE_Stomata_mask2former_swin-s.py',\n","              instance_detector_weight_path='Applications/Weights/INSTANCE_Stomata_mask2former_swin-s_2023August13.pth',\n","              instance_detector_threshold=0.6,\n","              segmentor_config_path='Applications/Configs/SEGMENTATION_Stomata_mask2former_swin-I.py',\n","              segmentor_weight_path='Applications/Weights/SEGMENTATION_Stomata_mask2former_swin-I_2023August15.pth').batch_predict()"]},{"cell_type":"markdown","metadata":{},"source":["## inference stomata annotations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import copy\n","from stomata_py.core.core import *\n","from stomata_py.core.stomata_traits import best_distance\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","\n","def get_aperture(seg_mask):\n","    a_pore = len(np.where(np.all(seg_mask == Stomata_Colors[3].mask_rgb, axis=-1))[0])  # pore area\n","    a_outer_ledge = len(np.where(np.all(seg_mask == Stomata_Colors[2].mask_rgb, axis=-1))[0]) + a_pore  # outer ledge area\n","    a_stomata = len(np.where(np.all(seg_mask == Stomata_Colors[1].mask_rgb, axis=-1))[0]) + a_outer_ledge  # stomata area\n","    stomata_pixel_ratio = a_stomata / seg_mask.shape[0] / seg_mask.shape[1] * 100  # as a quality check metric\n","    a_pore_absolute = a_pore * (1 / 8.0) ** 2  # pore area in square micrometer\n","    a_outer_ledge_absolute = a_outer_ledge * (1 / 8.0) ** 2  # outer ledge area in square micrometer\n","    a_stomata_absolute = a_stomata * (1 / 8.0) ** 2  # stomata area in square micrometer\n","    return [a_pore_absolute, a_outer_ledge_absolute, a_stomata_absolute, stomata_pixel_ratio]\n","\n","def text4name(patch_stitched, patch_name):\n","    text_image = np.zeros((80, patch_stitched.shape[1], 3), np.uint8)  # create a black image with the same width as the concatenated image for writing text\n","    font_scale, font_color, line_type, font = 0.6, (255, 255, 255), 2, cv2.FONT_HERSHEY_SIMPLEX  # noqa: define the font and line type\n","    (text_width, text_height) = cv2.getTextSize(patch_name, font, font_scale, line_type)[0]\n","    text_x = (text_image.shape[1] - text_width) // 2  # text x coordinate\n","    text_y = (text_image.shape[0] + text_height) // 2  # text y coordinate\n","    cv2.putText(text_image, patch_name, (text_x, text_y), font, font_scale, font_color, line_type)  # write the text to the image\n","    return cv2.vconcat([text_image, patch_stitched])\n","\n","\n","batch_results = pd.DataFrame(columns=['image name', 'image height', 'image width', 'scale (pixels/\\u03BCm)', 'stomata lenghth (\\u03BCm)', 'stomata width (\\u03BCm)',\n","                                    'outer_ledge lenghth (\\u03BCm)', 'outer_ledge width (\\u03BCm)', 'stomata area (\\u03BCm\\N{SUPERSCRIPT TWO})', 'outer ledge area (\\u03BCm\\N{SUPERSCRIPT TWO})',\n","                                    'pore area (\\u03BCm\\N{SUPERSCRIPT TWO})', 'openness (%)'])\n","\n","images_dir = 'Data//Training//Stomata//Peels//Stomata_mmseg//images'\n","masks_dir = 'Data//Training//Stomata//Peels//Stomata_mmseg//labels'\n","output_dir = 'Data//Training//Stomata//Peels//Stomata_mmseg//results'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","image_names = sorted(os.listdir(images_dir), key=str.casefold)\n","image_names = [name for name in image_names if any(name.lower().endswith(file_type) for file_type in image_types)]\n","image_paths = [os.path.join(images_dir, name) for name in image_names]\n","mask_paths = [os.path.join(masks_dir, name) for name in image_names]\n","\n","\n","for idx, image_path in tqdm(enumerate(image_paths), total=len(image_paths)):\n","\n","    image = imread_rgb(image_paths[idx])\n","    seg_mask = imread_rgb(mask_paths[idx])\n","\n","    refined_seg_mask = np.zeros((*seg_mask.shape[:2], 3), dtype=np.uint8)  # create a black image\n","    stomata_region = binary(color_select(seg_mask, seg_mask, Stomata_Colors[1].mask_rgb))\n","    ol_region = binary(color_select(seg_mask, seg_mask, Stomata_Colors[2].mask_rgb))\n","    pore_region = binary(color_select(seg_mask, seg_mask, Stomata_Colors[3].mask_rgb))\n","    refined_seg_mask[pore_region == 255] = Stomata_Colors[1].mask_rgb\n","    refined_seg_mask[ol_region == 255] = Stomata_Colors[1].mask_rgb  \n","    refined_seg_mask[stomata_region == 255] = Stomata_Colors[1].mask_rgb \n","\n","    stomata_contour, _ = cv2.findContours(binary(refined_seg_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n","\n","    refined_seg_mask = np.zeros((*seg_mask.shape[:2], 3), dtype=np.uint8)  # create a black image\n","    stomata_region = binary(color_select(seg_mask, seg_mask, Stomata_Colors[1].mask_rgb))\n","    ol_region = binary(color_select(seg_mask, seg_mask, Stomata_Colors[2].mask_rgb))\n","    pore_region = binary(color_select(seg_mask, seg_mask, Stomata_Colors[3].mask_rgb))\n","    refined_seg_mask[pore_region == 255] = Stomata_Colors[1].mask_rgb\n","    refined_seg_mask[ol_region == 255] = Stomata_Colors[1].mask_rgb  \n","\n","    ol_contour, _ = cv2.findContours(binary(refined_seg_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n","\n","    ol_contour_mask = np.zeros((*seg_mask.shape[:2], 3), dtype=np.uint8)  # create a black image\n","    cv2.drawContours(ol_contour_mask, ol_contour, -1, (255, 255, 255), 1)  # draw the outer ledge contour\n","    stomata_contour_mask = copy.deepcopy(ol_contour_mask)  # make a copy of the outer ledge contour\n","    cv2.drawContours(stomata_contour_mask, stomata_contour, -1, (255, 255, 255), 1)  # draw the stomata contour\n","    cv2.imwrite(os.path.join(output_dir, image_names[idx]), cv2.cvtColor(stomata_contour_mask, cv2.COLOR_RGB2BGR))\n","    \n","    stomata_lenghth_pixel, stomata_width_pixel, stomata_trait = best_distance(stomata_contour_mask)\n","    ol_lenghth_pixel, ol_width_pixel, ol_trait = best_distance(ol_contour_mask)\n","    stomata_lenghth, stomata_width = stomata_lenghth_pixel * (1 / 8.0), stomata_width_pixel * (1 / 8.0) \n","    ol_lenghth, ol_width = ol_lenghth_pixel * (1 / 8.0), ol_width_pixel * (1 / 8.0)\n","    patch_stitched = np.hstack((image , seg_mask, stomata_trait, ol_trait))\n","    patch_stitched = text4name(patch_stitched, image_names[idx])\n","    #cv2.imwrite(os.path.join(output_dir, image_names[idx]), cv2.cvtColor(patch_stitched, cv2.COLOR_RGB2BGR)) \n","    \n","    a_pore_absolute, a_ol_absolute, a_stomata_absolute, stomata_pixel_ratio = get_aperture(seg_mask)\n","\n","    result = {'image name': [image_names[idx]],\n","            'image height': [image.shape[0]],\n","            'image width': [image.shape[1]],\n","            'scale (pixels/\\u03BCm)': [8.0],\n","            'stomata lenghth (\\u03BCm)': [stomata_lenghth],\n","            'stomata width (\\u03BCm)': [stomata_width],\n","            'outer ledge lenghth (\\u03BCm)': [ol_lenghth],\n","            'outer ledge width (\\u03BCm)': [ol_width],\n","            'stomata area (\\u03BCm\\N{SUPERSCRIPT TWO})': [a_stomata_absolute],\n","            'outer ledge area (\\u03BCm\\N{SUPERSCRIPT TWO})': [a_ol_absolute],\n","            'pore area (\\u03BCm\\N{SUPERSCRIPT TWO})': [a_pore_absolute],\n","            'openness (%)': [a_ol_absolute / a_stomata_absolute * 100]}\n","    result = pd.DataFrame(data=result)\n","    batch_results = pd.concat([batch_results, result], axis=0) \n","batch_results.to_excel(os.path.join(output_dir, 'stomata aperture.xlsx'), index=False)\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","from stomata_py.core.core import imread_rgb\n","from stomata_py.core.stomata_traits_2 import GetDiameter\n","\n","input_dir = 'Data//Training//Stomata//Peels//Stomata_mmseg//results2'\n","file_names = os.listdir(input_dir)\n","file_paths = [os.path.join(input_dir, file_name) for file_name in file_names]\n","masks = [imread_rgb(file_path) for file_path in file_paths]\n","\n","for mask in tqdm(masks, total=len(masks)):\n","    stomata_lenghth, stomata_width, angle = GetDiameter(mask, shrink_ratio=1.2, line_thickness=3).pca(show_result=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["## inference starch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from stomata_py.inference_api.starch_inference import StarchSeeker\n","\n","StarchSeeker(input_dir='Data//Testing//Starch//Kidney//Lucia ERC 04_2021 N. exaltata Blue Light',\n","            output_name='Results starch',\n","            batch_size=40,\n","            detector_config_path='Applications//Configs//INSTANCE_mask2former_swin-s.py',\n","            detector_weight_path='Applications//Weights//INSTANCE_BOTH_mask2former_swin-s_2023.05.26.pth',\n","            detector_threshold=0.9,\n","            segmentor_config_path='Applications//Configs//SEMANTIC_mask2former_swin-I.py',\n","            segmentor_weight_path='Applications//Weights//SEMANTIC_BOTH_mask2former_swin-I_2023.05.27.pth',\n","            concatenate_excels=True).bacth_predict()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["J2OtvBLRa2D3","H0sxjxbvfWMb","nyr4y8aiw4oK","egEeiRr9uAj8","833D0mbi-Mqz","gEptYWuD8qjq","gz5wcgGScwPi","77_vyR9TC4p-","sbFmyqnaiSaj","gd9k1MHvooJ5"],"gpuClass":"premium","gpuType":"A100","machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
