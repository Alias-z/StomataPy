{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4fs8YYgAK_a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Starch detection from confocal stomatal images - prediction**\n",
    "\n",
    "Autors: Santelia Lab at ETH Zurich\n",
    "\n",
    "Contact: hongyuan.zhang@usys.ethz.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzDGiv8CAQ9V",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reference\n",
    "[MMDetection](https://github.com/open-mmlab/mmdetection)\n",
    "<br><br>\n",
    "[MMSegmentation](https://github.com/open-mmlab/mmsegmentation)\n",
    "<br><br>\n",
    "[Instance segmentation on COCO benchmark](https://paperswithcode.com/sota/instance-segmentation-on-coco)\n",
    "<br><br>\n",
    "[Semantic segmentation on ADE20K benchmark](https://paperswithcode.com/sota/semantic-segmentation-on-ade20k)\n",
    "<br><br>\n",
    "[Segment Anything (Kirillov, Alexander et al., 2023)](https://arxiv.org/abs/2112.01527)\n",
    "<br><br>\n",
    "[Masked-attention mask transformer for universal image segmentation (Cheng, Bowen, et al., 2022)](https://arxiv.org/abs/2112.01527)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx3NgLkhBNee",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### connect to google drive folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683612224764,
     "user": {
      "displayName": "Hongyuan Zhang",
      "userId": "04496592888494956107"
     },
     "user_tz": -120
    },
    "id": "sJpS1kVmBQau",
    "outputId": "84cad150-c8b7-4377-d31a-f72660091ece",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "####### code block 1 ########\n",
    "\n",
    "#from google.colab import drive; drive.mount('/content/drive')\n",
    "#%cd /content/drive/MyDrive/GCstarch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683612437245,
     "user": {
      "displayName": "Hongyuan Zhang",
      "userId": "04496592888494956107"
     },
     "user_tz": -120
    },
    "id": "g7JEwa2sAL0M",
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### code block 2 ########\n",
    "\n",
    "#@title **define parameters** {run: 'auto'}\n",
    "\n",
    "#@markdown  **Mandatory parameters**\n",
    "\n",
    "user = 'Hongyuan' #@param ['Carlo', 'Erik', 'Hongyuan', 'Lucia', 'Trang'] {allow-input: true}\n",
    "stomata_type = 'Both' #@param ['Kidney', 'Dumbbell', 'Both']\n",
    "input_dir = 'Z-stacks' #@param\n",
    "\n",
    "#@markdown  **Optional**\n",
    "output_name = 'Results' #@param {type: 'string'}\n",
    "image_types = ['.tif', '.czi', '.lif'] #@param\n",
    "batch_size = 20 #@param\n",
    "use_SAM = False #@param ['True', 'False'] {type: 'raw'}\n",
    "\n",
    "Instance_configs = 'Applications//Configs//INSTANCE_mask2former_swin-s.py'\n",
    "Semantic_configs = 'Applications//Configs//SEMANTIC_mask2former_swin-I.py'\n",
    "\n",
    "if stomata_type == 'Kidney':    \n",
    "    Instance_weights = 'Applications//Weights//INSTANCE_KIDNEY_mask2former_swin-s_2023.05.15.pth'\n",
    "    Semantic_weights = 'Applications//Weights//SEMANTIC_KIDNEY_mask2former_swin-I_2023.03.13.pth'\n",
    "elif stomata_type == 'Dumbbell':\n",
    "    Instance_weights = 'Applications//Weights//INSTANCE_DUMBBELL_mask2former_swin-s_2023.03.13.pth'\n",
    "    Semantic_weights = 'Applications//Weights//SEMANTIC_DUMBBELL_mask2former_swin-I_2023.03.14.pth'\n",
    "elif stomata_type == 'Both':\n",
    "    Instance_weights = 'Applications//Weights//INSTANCE_BOTH_mask2former_swin-s_2023.05.26.pth'\n",
    "    Semantic_weights = 'Applications//Weights//SEMANTIC_BOTH_mask2former_swin-I_2023.05.27.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRL-hVqnAjE0",
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### install requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## test zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import napari\n",
    "import numpy as np\n",
    "from stomata_py.GCstarch.GCstarch3D import GCstarch3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: Applications//Weights//INSTANCE_BOTH_mask2former_swin-s_2023.05.26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\mambaforge\\envs\\stomatapy\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 40/40 [00:03<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: Applications//Weights//SEMANTIC_BOTH_mask2former_swin-I_2023.05.27.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:09<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 5.857448577880859\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Points layer 'points2' at 0x2ded5249d60>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_path = os.path.join(input_dir, 'Arabidopsis t0 1.tif')\n",
    "starch_GC1_zxy, starch_GC2_zxy, stack_zxy , scale_zxy, v_starch_GC1, v_starch_GC2 = GCstarch3D(stack_path, Instance_configs, Instance_weights, Semantic_configs, Semantic_weights, n=3)\n",
    "\n",
    "points1 = np.array([[15, 10]])\n",
    "points2 = np.array([[10, 40]])\n",
    "features1 = {'starch volume': np.array([v_starch_GC1]), 'guard cell': np.array([1])}\n",
    "features2 = {'starch volume': np.array([v_starch_GC2]), 'guard cell': np.array([2])}\n",
    "\n",
    "text1 = {\n",
    "    'string': 'Guard cell {guard cell} \\n starch volume: {starch volume:.2f} (µm³)',\n",
    "    'size': 10,\n",
    "    'color': 'lightblue',\n",
    "    'translation': np.array([-2, 0]),\n",
    "}\n",
    "text2 = {\n",
    "    'string': 'Guard cell {guard cell} \\n starch volume: {starch volume:.2f} (µm³)',\n",
    "    'size': 10,\n",
    "    'color': 'pink',\n",
    "    'translation': np.array([-2, 0]),\n",
    "}\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(stack_zxy, name='raw', scale=scale_zxy)\n",
    "viewer.layers[0].colormap = 'bone'\n",
    "viewer.add_labels(starch_GC1_zxy, name='starch guard cell 1', scale=scale_zxy, opacity=0.5, blending='additive', rendering='translucent')\n",
    "viewer.add_labels(starch_GC2_zxy, name='starch guard cell 2', scale=scale_zxy, opacity=0.5, blending='additive',  rendering='translucent')\n",
    "viewer.add_points(points1, features=features1, text=text1, size=0.5, edge_width=0, edge_width_is_relative=False)\n",
    "viewer.add_points(points2, features=features2, text=text2, size=0.5, edge_width=0, edge_width_is_relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "path = 'drive'\n",
    "starch_GC1_zxy = np.load(os.path.join(path, 'starch_GC1_zxy.npy'))\n",
    "starch_GC2_zxy = np.load(os.path.join(path, 'starch_GC2_zxy.npy'))\n",
    "stack_zxy = np.load(os.path.join(path, 'stack_zxy.npy'))\n",
    "scale_zxy = np.load(os.path.join(path, 'scale_zxy.npy'))\n",
    "v_starch_GC1 = np.load(os.path.join(path, 'v_starch_GC1.npy'))\n",
    "v_starch_GC2 = np.load(os.path.join(path, 'v_starch_GC2.npy'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOfKHnvTCBDH4+e3QHwOz5O",
   "collapsed_sections": [
    "iRL-hVqnAjE0"
   ],
   "machine_shape": "hm",
   "mount_file_id": "1ZGD0sNPCemdEHsW06K-UcbC8ALT0sDxX",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}